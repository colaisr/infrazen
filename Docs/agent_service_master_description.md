# InfraZen Agent Service ‚Äì Consolidated Product Description

## 1. Vision & Positioning
- **Product:** InfraZen Agent Service ‚Äì conversational FinOps assistant for InfraZen.
- **Primary Promise:** Drive faster, safer cost optimization decisions via context-aware chats and auto-generated recommendations, grounded in a user‚Äôs real infrastructure, prices, and analytics.
- **Target Users:** FinOps practitioners, DevOps, engineering managers, finance stakeholders.
- **Scenarios (MVP):**
  1) Recommendation text generator (deterministic, sync)
  2) Recommendation-specific chat (context-aware, multi-modal)
  3) Analytics page chat (global insights, multi-modal)

## 2. Requirements Summary
- **Persona & Tone:** Senior FinOps with deep sysadmin understanding; balances savings, effort, and risk.
- **Data Awareness:** Per-user scoped access to resources, recommendations, snapshots, prices, analytics.
- **Tooling:** Agent must call tool-scoped, read-only APIs; future action tools gated with confirmation.
- **Multi-Model:** Pluggable LLMs via a provider abstraction; start with OpenRouter; support direct and local (Ollama/GigaChat) later.
- **Multi-Modal:** Accept pasted images/screenshots; use vision-capable models for chart/invoice/screens review.
- **Security:** Role checks, demo-user read-only, tenant isolation, audit logs, output validation.
- **Latency & Cost:** Streaming responses, timeouts, retries, cost tracking, provider fallback.
- **RAG-Ready:** Index selected reports, summaries, and safe DB views for retrieval-augmented answers.

## 3. Selected Stack (All open-source and free)
- **Service:** FastAPI (HTTP/REST + WebSocket streaming)
- **Agent Orchestration:** LangGraph (tool-using, stateful agents; MIT)
- **RAG (later phase):** LlamaIndex (MIT) or native retrievers
- **Model Abstraction:** LiteLLM (MIT) with OpenRouter adapter as default
- **Vector Store:** Chroma (Apache-2.0) initially; pgvector later for production
- **Session/Cache:** Redis or Valkey (OSS drop-in)
- **Proxy:** Nginx
- **Observability:** Prometheus + Grafana
- **Local LLM (optional):** Ollama or vLLM
- **Provider:** OpenRouter (one API, many models/providers). Reference: https://openrouter.ai/

## 4. High-Level Architecture
```
Browser (UI)  ‚áÑ  InfraZen App (Flask)  ‚áÑ  Agent Service (FastAPI + LangGraph)
                                         ‚îú‚îÄ LLM Gateway (LiteLLM/OpenRouter, direct, local)
                                         ‚îú‚îÄ Tools SDK (read-only data access via InfraZen internal APIs)
                                         ‚îú‚îÄ Context Packs (resource, recommendation, analytics)
                                         ‚îú‚îÄ RAG (vector DB) [later]
                                         ‚îî‚îÄ Redis/Valkey (sessions) + Storage (images)
```

### 4.1 Modules
- **API Layer:** REST endpoints for sync generations; WebSocket for chats.
- **LLM Gateway:** Provider-agnostic client with retries, fallbacks, cost/latency logging; models configurable.
- **Tools SDK:** Registry for tools with JSON schemas, rate limits, auth scopes, optional tool prompts.
- **Context Packs:** Safe, shaped snapshots of user data for scenarios (resource, rec, analytics) with minimal tokens.
- **Guardrails:** Role checks, demo read-only, PII filtering, output schema validation, audit trail.
- **RAG Pipeline (future):** Index curated content (reports, summaries, safe views) with user/tenant scoping.

## 5. Data Access & Security
- **Tool-Scoped Access (Recommended):** Agent calls internal InfraZen APIs (read-only) instead of direct DB.
  - Benefits: security, stability, performance, caching, consistent schemas.
- **Auth:** Service-to-service JWT (rotating secret); per-request user context; strict tenant isolation.
- **Roles:** Enforce InfraZen roles; demo users are read-only.
- **Auditing:** Log each tool call with inputs, outputs (truncated), cost, latency, and user context.

## 6. Scenarios & Behavior
### 6.1 Scenario 1 ‚Äì AI-Generated Recommendation Texts ‚úÖ IMPLEMENTED

**Overview:**
Replace hardcoded recommendation descriptions with AI-generated, context-aware texts that focus on economics, specs, and actionable insights. Generated once during main sync and stored in database for instant display.

**Business Logic:**
- **Trigger:** During main sync process, immediately after each recommendation is created and committed
- **Input:** `recommendation_id`
- **Output:** Two HTML-formatted texts:
  - `short_description_html` (~60-80 chars) - for collapsed card view
  - `detailed_description_html` (~200-300 chars) - replaces "–ü–æ—è—Å–Ω–µ–Ω–∏—è" and "–ú–µ—Ç—Ä–∏–∫–∏" sections
- **Storage:** Stored in `optimization_recommendations` table alongside recommendation data
- **Display:** Pre-generated text rendered instantly in UI (no async loading, no token waste)
- **Fallback:** If agent fails, recommendation still created without AI text (shows original description)

#### 6.1.1 Implementation Architecture

```
Main Sync Process:
   ‚Üì
Create Recommendation ‚Üí db.session.commit()
   ‚Üì
Call: generate_recommendation_text(rec.id)
   ‚Üì
   ‚îú‚îÄ HTTP POST ‚Üí Agent Service (/v1/generate/recommendation-text)
   ‚îÇ     ‚Üì
   ‚îÇ  Agent fetches data (within Flask app context):
   ‚îÇ     ‚îú‚îÄ Recommendation (type, savings, target provider/SKU)
   ‚îÇ     ‚îú‚îÄ Resource (specs from provider_config: vcpus, ram_gb, storage_gb)
   ‚îÇ     ‚îú‚îÄ Current Provider (name, region)
   ‚îÇ     ‚îú‚îÄ Parse insights & metrics (Python dict strings ‚Üí JSON)
   ‚îÇ     ‚Üì
   ‚îÇ  Route to appropriate prompt builder:
   ‚îÇ     ‚îú‚îÄ Price comparison ‚Üí build_recommendation_prompt()
   ‚îÇ     ‚îî‚îÄ Cleanup ‚Üí build_cleanup_prompt()
   ‚îÇ     ‚Üì
   ‚îÇ  Call LLM via OpenRouter (gpt-4o-mini)
   ‚îÇ     ‚Üì
   ‚îÇ  Return JSON: {short_description_html, detailed_description_html}
   ‚Üì
Store AI text in DB:
   rec.ai_short_description = result['short_description_html']
   rec.ai_detailed_description = result['detailed_description_html']
   rec.ai_generated_at = datetime.utcnow()
   db.session.commit()
```

#### 6.1.2 Recommendation Types & Prompts

**1. Price Comparison (Cross-Provider Migration)**

Types: `price_compare_cross_provider`, `price_compare_same_provider`

*FinOps Focus:* Economics and comparable configuration

*AI Text Format:*
- **Short:** `"{target_provider} –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –∞–Ω–∞–ª–æ–≥ –∑–∞ {target_price} ‚ÇΩ/–º–µ—Å –≤–º–µ—Å—Ç–æ —Ç–µ–∫—É—â–∏—Ö {current_price} ‚ÇΩ/–º–µ—Å"`
- **Detailed:** `"–≠–∫–æ–Ω–æ–º–∏—è {savings} ‚ÇΩ/–º–µ—Å –ø—Ä–∏ –ø–µ—Ä–µ–Ω–æ—Å–µ {resource_type} {resource_name} –≤ {target_provider}. –°—Ö–æ–∂–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (X CPU, Y GB RAM, Z GB HD) —Ç–∞–º —Å—Ç–æ–∏—Ç {target_price} ‚ÇΩ/–º–µ—Å"`

*Example:*
```
Short: selectel –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –∞–Ω–∞–ª–æ–≥ –∑–∞ 5,349 ‚ÇΩ/–º–µ—Å –≤–º–µ—Å—Ç–æ —Ç–µ–∫—É—â–∏—Ö 5,610 ‚ÇΩ/–º–µ—Å
Detailed: –≠–∫–æ–Ω–æ–º–∏—è 261 ‚ÇΩ/–º–µ—Å –ø—Ä–∏ –ø–µ—Ä–µ–Ω–æ—Å–µ —Å–µ—Ä–≤–µ—Ä–∞ office –≤ selectel. 
          –°—Ö–æ–∂–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (4 CPU, 8.0 GB RAM, 92.0 GB HD) —Ç–∞–º —Å—Ç–æ–∏—Ç 5,349 ‚ÇΩ/–º–µ—Å
```

*Key Data Extraction:*
- Resource specs: `provider_config.vcpus`, `provider_config.ram_gb`, `provider_config.total_storage_gb`
- Current cost: `resource.effective_cost`
- Target cost: `insights.top2[0].monthly` or `metrics.target_monthly`
- Similarity: `metrics.similarity √ó 100%`

**2. Cleanup Recommendations (Resource Deletion)**

Types: `cleanup_old_snapshot`, `cleanup_unused_ip`, `cleanup_unused_volume`, `cleanup_stopped`

*FinOps Focus:* Cost elimination with delicate mention of wasted budget

*AI Text Format:*
- **Short:** `"–≠–∫–æ–Ω–æ–º–∏—è {savings} ‚ÇΩ/–º–µ—Å –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º–æ–≥–æ {resource_type}"`

- **Detailed (Snapshots & IPs with age data):**
  `"–≠–∫–æ–Ω–æ–º–∏—è {savings} ‚ÇΩ/–º–µ—Å –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ {resource_type} {resource_name}. {Type} –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É–∂–µ X –¥–Ω–µ–π (—Ä–∞–∑–º–µ—Ä Y GB), –∑–∞ —ç—Ç–æ –≤—Ä–µ–º—è –Ω–∞ –Ω–µ–≥–æ —É–∂–µ –±—ã–ª–æ –ø–æ—Ç—Ä–∞—á–µ–Ω–æ {wasted} ‚ÇΩ."`

- **Detailed (Stopped Servers - no age data):**
  `"–≠–∫–æ–Ω–æ–º–∏—è {savings} ‚ÇΩ/–º–µ—Å –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞ {resource_name}. –°–µ—Ä–≤–µ—Ä –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Å—Ç–∞—Ç—É—Å–µ STOPPED –∏ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç –ø–æ—Ç—Ä–µ–±–ª—è—Ç—å —Å—Ä–µ–¥—Å—Ç–≤–∞ –Ω–∞ —Ö—Ä–∞–Ω–µ–Ω–∏–µ."`

*Examples:*
```
Snapshot:
  Short: –≠–∫–æ–Ω–æ–º–∏—è 1,709 ‚ÇΩ/–º–µ—Å –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º–æ–≥–æ —Å–Ω–∞–ø—à–æ—Ç–∞
  Detailed: –≠–∫–æ–Ω–æ–º–∏—è 1,709 ‚ÇΩ/–º–µ—Å –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ —Å–Ω–∞–ø—à–æ—Ç–∞ gitdisk-1740816592565. 
            –°–Ω–∞–ø—à–æ—Ç –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É–∂–µ 248 –¥–Ω–µ–π (—Ä–∞–∑–º–µ—Ä 507 GB), –∑–∞ —ç—Ç–æ –≤—Ä–µ–º—è 
            –Ω–∞ –Ω–µ–≥–æ —É–∂–µ –±—ã–ª–æ –ø–æ—Ç—Ä–∞—á–µ–Ω–æ 14,119 ‚ÇΩ.

IP Address:
  Short: –≠–∫–æ–Ω–æ–º–∏—è 241 ‚ÇΩ/–º–µ—Å –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º–æ–≥–æ IP-–∞–¥—Ä–µ—Å–∞
  Detailed: –≠–∫–æ–Ω–æ–º–∏—è 241 ‚ÇΩ/–º–µ—Å –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ IP-–∞–¥—Ä–µ—Å–∞ gitlab_new. 
            IP –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É–∂–µ 547 –¥–Ω–µ–π, –∑–∞ —ç—Ç–æ –≤—Ä–µ–º—è –Ω–∞ –Ω–µ–≥–æ —É–∂–µ –±—ã–ª–æ –ø–æ—Ç—Ä–∞—á–µ–Ω–æ 4,394 ‚ÇΩ.

Stopped Server:
  Short: –≠–∫–æ–Ω–æ–º–∏—è 1,289 ‚ÇΩ/–º–µ—Å –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞
  Detailed: –≠–∫–æ–Ω–æ–º–∏—è 1,289 ‚ÇΩ/–º–µ—Å –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞ punch-dev-monitoring-1. 
            –°–µ—Ä–≤–µ—Ä –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Å—Ç–∞—Ç—É—Å–µ STOPPED –∏ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç –ø–æ—Ç—Ä–µ–±–ª—è—Ç—å —Å—Ä–µ–¥—Å—Ç–≤–∞ –Ω–∞ —Ö—Ä–∞–Ω–µ–Ω–∏–µ.
```

*Key Data Extraction:*
- Age: `insights.age_days` (available for snapshots, IPs, volumes; NOT for stopped servers)
- Size: `insights.size_gb` (for snapshots, volumes)
- Wasted amount: calculated as `(monthly_savings √ó age_days) / 30`
- Status: `metrics.status` (for stopped servers)

*Special Handling:*
- Stopped servers: no age/wasted data (we don't know WHEN they were stopped), focus on current status
- Concrete resource types: "–°–Ω–∞–ø—à–æ—Ç" (not "–†–µ—Å—É—Ä—Å"), "IP" (not "IP-–∞–¥—Ä–µ—Å" in second sentence)
- No redundant fluff: removed "–£–¥–∞–ª–µ–Ω–∏–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é –∏—Å–∫–ª—é—á–∏—Ç —ç—Ç–∏ —Ä–∞—Å—Ö–æ–¥—ã" (obvious)

#### 6.1.3 Prompt Engineering Principles

**FinOps Persona:**
- 10+ years FinOps experience
- Deep sysadmin understanding
- Balances savings, implementation effort, and risks
- Professional, conversational tone (not robotic templates)

**Writing Style:**
- **Focus on Economics:** Start with savings amount, always highlighted
- **Natural Language:**
  - ‚úÖ "–ø—Ä–∏ –ø–µ—Ä–µ–Ω–æ—Å–µ" (when migrating) vs ‚ùå "–ø—Ä–∏ –º–∏–≥—Ä–∞—Ü–∏–∏"
  - ‚úÖ "—Ç–∞–º —Å—Ç–æ–∏—Ç" (costs there) vs ‚ùå "—Å—Ç–æ–∏–º–æ—Å—Ç—å —Å–æ—Å—Ç–∞–≤–∏—Ç"
  - ‚úÖ "—Å—Ö–æ–∂–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è" (similar config) with real values in parentheses
  - ‚úÖ "–Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è" (not used) vs ‚ùå "—Å—É—â–µ—Å—Ç–≤—É–µ—Ç" (exists)
- **Concrete, Not Generic:**
  - ‚úÖ "–°–Ω–∞–ø—à–æ—Ç –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è" vs ‚ùå "–†–µ—Å—É—Ä—Å –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è"
  - ‚úÖ "(4 CPU, 7 GB RAM, 105 GB HD)" vs ‚ùå "(CPU/RAM/HD)"
- **Delicate About Waste:**
  - ‚úÖ "—É–∂–µ –±—ã–ª–æ –ø–æ—Ç—Ä–∞—á–µ–Ω–æ" vs ‚ùå "–ø–æ—Ç—Ä–∞—á–µ–Ω–æ –≤–ø—É—Å—Ç—É—é"
  - Only mention if age > 30 days and amount > 0
- **No Redundancy:**
  - ‚ùå "–£–¥–∞–ª–µ–Ω–∏–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é –∏—Å–∫–ª—é—á–∏—Ç —ç—Ç–∏ —Ä–∞—Å—Ö–æ–¥—ã" - removed
  - ‚ùå "–æ—Å–≤–æ–±–æ–¥–∏—Ç —Å—Ä–µ–¥—Å—Ç–≤–∞ –¥–ª—è –±–æ–ª–µ–µ –Ω—É–∂–Ω—ã—Ö –∑–∞–¥–∞—á" - removed

**HTML Formatting:**
- `<strong>` for prices, savings, wasted amounts
- `<span class='provider-name'>` for provider names
- No lists (ul/ol), only inline text
- Preserve HTML in database and render safely in UI

**Validation:**
- LLM returns clean JSON (no markdown code blocks)
- Fallback texts if LLM fails to parse or returns invalid JSON
- Error logged but sync continues (non-fatal)

#### 6.1.4 Database Schema

```sql
ALTER TABLE optimization_recommendations
ADD COLUMN ai_short_description TEXT NULL,
ADD COLUMN ai_detailed_description TEXT NULL,
ADD COLUMN ai_generated_at DATETIME NULL;
```

**Migration:** `b8136224cf9c_add_ai_text_fields_to_recommendations.py`

#### 6.1.5 Files Involved

**Main App:**
- `app/core/recommendations/orchestrator.py` - calls AI generator after rec creation (line 353-366)
- `app/core/services/ai_text_generator.py` - HTTP client for agent service
- `app/core/models/recommendations.py` - added 3 AI text columns
- `app/web/main.py` - passes `enable_ai_recommendations` and `agent_service_url` to template
- `app/config.py` - feature flags: `ENABLE_AI_RECOMMENDATIONS`, `AGENT_SERVICE_URL`
- `app/templates/recommendations.html` - passes config to JS
- `app/static/js/recommendations.js` - renders `rec.ai_short_description` and `rec.ai_detailed_description`

**Agent Service:**
- `agent_service/api/recommendations.py` - `POST /v1/generate/recommendation-text` endpoint
- `agent_service/core/recommendation_generator.py` - orchestrates data fetch + LLM call
- `agent_service/tools/data_access.py` - fetches recommendation, parses provider_config for specs
- `agent_service/llm/gateway.py` - LLM abstraction (OpenRouter, with fallback support)
- `agent_service/llm/prompts.py` - separate prompt builders:
  - `build_recommendation_prompt()` - for price comparison
  - `build_cleanup_prompt()` - for cleanup/deletion

**Utilities:**
- `scripts/generate_ai_text_for_existing.py` - backfill AI text for historical recommendations

#### 6.1.6 Performance & Cost

- **Latency:** ~2-4 seconds per recommendation during sync
- **Cost:** ~1,700 tokens per recommendation (gpt-4o-mini: ~$0.0003 per rec)
- **Optimization:** Generated once during sync, stored, reused forever (no repeated calls)
- **Token Savings vs Live Generation:** 100x+ (no regeneration on every page load)
- **Model:** `openai/gpt-4o-mini` via OpenRouter (fast, cheap, good quality)

### 6.2 Scenario 2 ‚Äì Recommendation Chat (Context-Aware, Multi-Modal)
- **Session:** `user_id` + `recommendation_id` (+ provider scope)
- **Context Pack:** Recommendation + resource + top-5 alternatives, normalized spec parity, latest snapshot facts, relevant prices.
- **Tools:** get_recommendation, get_resource, get_latest_snapshot, list_top_alternatives(limit=5), estimate_migration_effort, generate_step_plan
- **Behavior:** Explain trade-offs, effort vs savings, propose staged plan; accept image pastes (screenshots, consoles).
- **Transport:** WebSocket streaming; Redis for session; transcript persisted.

### 6.3 Scenario 3 ‚Äì Analytics Page Chat (Global Insights, Multi-Modal)
- **Session:** `user_id` + `time_range` + `page_context`
- **Context Pack:** KPIs, charts, cost trends, anomalies, top N recommendations; optional RAG for narrative tone.
- **Tools:** get_analytics_overview, get_cost_trends, get_service_breakdown, get_anomalies, summarize_top_recommendations
- **Behavior:** Answer questions about charts/KPIs; produce short narratives; accept pasted chart images.
- **Future:** One-click ‚ÄúGenerate Report‚Äù (HTML/PDF) similar to sample.

## 7. Tools Catalog (v1)
- `get_user_context(user_id)` ‚Äì base profile, roles, preferences (read-only)
- `get_resource(resource_id)` ‚Äì spec, provider, tags, monthly cost snapshot
- `get_latest_snapshot(resource_id|provider_id)` ‚Äì utilization, state changes
- `list_top_alternatives(resource_id, limit=5)` ‚Äì normalized spec matching and price deltas
- `get_prices_for_skus(skus[])` ‚Äì current prices with regions/currencies
- `get_recommendation(recommendation_id)` ‚Äì current text, savings, classification
- `get_analytics_overview(user_id, range)` ‚Äì KPIs, breakdowns, anomalies
- `estimate_migration_effort(rec|resource)` ‚Äì heuristic effort score + notes
- `generate_step_plan(rec)` ‚Äì ordered steps with risk flags

All tools:
- Have JSON schemas, rate limits, per-tool prompts (optional), and strict return schemas.
- Are read-only by default; action tools will require explicit user confirmation.

## 8. Prompts & Policies
- **System Persona:** ‚ÄúSenior FinOps with 10+ years; deep sysadmin experience; clear, concise, and actionable.‚Äù
- **Tool Prompts:** Optional preambles for each tool to guide usage and constraints.
- **Output Validation:** Structured JSON where applicable; enforce numeric formats and currency symbols.
- **Guardrails:** Avoid speculative claims; cite tool-derived facts; highlight effort/risk alongside savings.

## 9. API Surface (Initial)
- `POST /v1/generate/recommendation-text` ‚Äì Sync generation for Scenario 1
- `GET /v1/chat/ws?session=...` ‚Äì WebSocket chat for Scenarios 2‚Äì3 (with auth token)
- `POST /v1/chat/start` ‚Äì Create chat session (scope: rec or analytics)
- `POST /v1/upload` ‚Äì Image upload endpoint (multipart/base64), returns handle for multi-modal models
- `GET /v1/health` ‚Äì Liveness/readiness

Notes:
- Streaming tokens over WebSocket; partial deltas + tool call events.
- Strict auth and user scoping; transcripts stored with tenant boundary.

## 10. Deployment Model
### 10.1 Same Server (Phase 1 ‚Äì Fastest)
- Separate process and port (e.g., 8001), proxied at `/agent/` via Nginx.
- Independent systemd unit: `infrazen-agent.service`.
- Separate env file: `config.agent.env` (OpenRouter key, model names, InfraZen API URL, JWT secret).

### 10.2 Separate Server / K8s (Phase 2 ‚Äì Scalable)
- Own CI job; horizontal scaling; Redis for sessions; Prometheus metrics.
- Same service-to-service auth and internal API contracts.

## 11. CI/CD
- Monorepo with two pipelines:
  - App pipeline (Flask app)
  - Agent pipeline (Agent Service)
- Dev convenience: combined ‚Äúdeploy both‚Äù path.
- Version independently; shared changelog sections.
- Secrets via environment (server), not in repo.

## 12. Configuration Keys (Initial)
- `AGENT_PORT=8001`
- `AGENT_ENV=dev|prod`
- `AGENT_INTERNAL_API_BASE=http://127.0.0.1:5001/internal` (or service DNS)
- `AGENT_SERVICE_JWT_SECRET=...`
- `LLM_PROVIDER=openrouter|openai|anthropic|ollama|gigachat`
- `LLM_MODEL_TEXT=...` (e.g., openrouter/gpt-5)
- `LLM_MODEL_VISION=...` (e.g., openrouter/gemini-2.5-pro)
- `OPENROUTER_API_KEY=...` (if using OpenRouter)
- `REDIS_URL=redis://127.0.0.1:6379/0` (or Valkey)
- `VECTOR_STORE=chroma|pgvector`
- `LOG_LEVEL=INFO`

## 13. Observability & Cost Control
- **Metrics:** request latency, tool call counts, LLM token usage/costs, error rates, cache hit ratio.
- **Logs:** structured JSON with correlation IDs, per-tool audits.
- **Alerts:** latency spikes, tool error bursts, cost anomalies per provider/model.

## 14. Risks & Mitigations
- **Tool sprawl:** Use a curated catalog and versioning (`tool@vN`).
- **Data leakage:** Tool-scoped APIs only; enforce tenant scoping and PII filters.
- **Model variance:** Use OpenRouter routing + fallback; keep deterministic sync path for Scenario 1.
- **Latency/cost:** Streaming, caching, provider fallbacks, max tokens and timeouts.

## 15. Roadmap & Extensions
- **Short-term:** Add RAG for analytics narratives; report generator (HTML/PDF) on demand; effort estimators per resource type.
- **Mid-term:** Action tools with confirmations (e.g., create JIRA task, draft change plan docs).
- **Long-term:** Fine-tuned models, per-tenant adapters, and on-prem LLM options at scale.

---

### Appendix A ‚Äì Model Strategy (Initial)
- Text + tools: GPT‚Äëclass or Claude Sonnet via OpenRouter (cost/perf tuned).
- Vision: Gemini 2.5 Pro or Sonnet Vision via OpenRouter.
- Local: Ollama profiles for dev air-gapped testing.

Reference: OpenRouter ‚Äì The Unified Interface for LLMs: https://openrouter.ai/

## 16. Implementation Plan & Milestones

This section tracks execution progress. We will update checkboxes as we proceed, refine scope when discoveries occur, and clean up progress notes at the end to leave a final specification.

### Milestone 1 ‚Äì Skeleton + Local/Server Validation ‚úÖ COMPLETE
- [x] Scaffold agent_service skeleton (FastAPI, LangGraph) with:
  - [x] Health endpoint (`GET /v1/health`)
  - [x] WebSocket echo (`/v1/chat/ws`) for basic connectivity
  - ‚úÖ **Created:** `agent_service/` directory structure with FastAPI app, health & readiness checks, WebSocket echo endpoint
- [x] Add config assets:
  - [x] `requirements-agent.txt` (FastAPI, LangGraph, LiteLLM, Redis, Chroma, etc.)
  - [x] `Dockerfile` (Python 3.10-slim with health check)
  - [x] `config.agent.env.sample` (template for all required env vars)
- [x] Minimal test UI page in the app and an app route that pings the agent
  - ‚úÖ **Created:** `/agent-test` route in Flask app with test page for health & WebSocket testing
- [x] Local run scripts: app on 5001, agent on 8001 behind reverse proxy
  - ‚úÖ **Created:** `run_both.sh` and `stop_both.sh` for unified local development
  - ‚úÖ **Verified:** Both services running and healthy (agent: port 8001, app: port 5001)
- [x] Server prep:
  - [x] Nginx location `/agent/` ‚Üí upstream `127.0.0.1:8001` (with WebSocket support, long timeouts)
  - [x] systemd `infrazen-agent.service` and `config.agent.env`
  - ‚úÖ **Production:** Nginx proxying HTTPS traffic to agent on port 8001
- [x] Deploy agent locally and validate health/readiness
  - ‚úÖ **Committed:** dec0baa - Agent Service skeleton with 23 files
  - ‚úÖ **Pushed:** to master branch
  - ‚úÖ **Production:** Both services running, health checks passing

Definition of done: ‚úÖ COMPLETE - health endpoint OK, WebSocket echo works, test page shows "connected to agent", production deployment successful.

### Milestone 2 ‚Äì CI/CD for Agent (No Impact to App) ‚úÖ PARTIAL
- [x] Extend `deploy.sh` to support `app|agent|both` with idempotent steps and rollback
  - ‚úÖ **Production:** Deploy script supports `./deploy.sh app|agent|both`
  - ‚úÖ **Health Checks:** Both services have automated health validation
  - ‚úÖ **Zero-downtime:** App uses systemctl reload, Agent restarts gracefully
- [ ] Add separate CI job for agent (build, push, restart) independent of app pipeline
- [ ] Wire agent secrets/env in CI without touching existing app secrets

Definition of done: pushing an agent-only change deploys agent; app pipeline remains unchanged.

### Milestone 3 ‚Äì Joint Deploy Test ‚úÖ COMPLETE
- [x] Make a trivial change to both app and agent; deploy both
- [x] Verify both changes delivered and healthy without downtime
  - ‚úÖ **Tested:** Console message in dashboard.js + message field in health endpoint
  - ‚úÖ **Verified:** Both changes deployed successfully with `./deploy.sh both`
  - ‚úÖ **Zero downtime:** App reloaded, agent restarted, both healthy

Definition of done: ‚úÖ COMPLETE - both services reflect changes; clean logs; zero app downtime.

### Milestone 4 ‚Äì LLM Recommendation Text (with Fallback) ‚úÖ COMPLETE
- [x] Implement `POST /v1/generate/recommendation-text` with tool-scoped reads
  - ‚úÖ **Tools:** Data access for recommendations, resources, providers with Python dict parsing
  - ‚úÖ **LLM Gateway:** OpenRouter integration with gpt-4o-mini
  - ‚úÖ **Prompts:** FinOps persona with HTML formatting, Russian language
  - ‚úÖ **Sanitization:** Basic HTML whitelist (strong, span, em, br)
- [x] UI feature flag to switch from hardcoded text to agent output; preserve fallback
  - ‚úÖ **Config:** ENABLE_AI_RECOMMENDATIONS and AGENT_SERVICE_URL flags
  - ‚úÖ **UI:** Async fetch with caching, replaces short description in collapsed cards
  - ‚úÖ **Details:** AI detailed description + "–û–±—Å—É–¥–∏—Ç—å —Å FinOps" button in expanded view
  - ‚úÖ **Fallback:** Graceful degradation to original –ü–æ—è—Å–Ω–µ–Ω–∏—è/–ú–µ—Ç—Ä–∏–∫–∏ if AI fails
  - ‚úÖ **Tested:** Working with gpt-4o-mini, ~830 tokens/call, correct prices and formatting
  - ‚úÖ **Commits:** c62094e (API), c419c9f (UI)

Definition of done: ‚úÖ COMPLETE - flag ON shows agent text with HTML formatting; OFF uses current implementation.

### Milestone 5 ‚Äì Recommendation Chat (Context-Aware, Multi-Modal) üöß IN PROGRESS

**Overview:**
WebSocket-based chat for discussing specific recommendations. User can ask questions, request analysis, and upload screenshots. Agent has read-only access to recommendation, resource, and pricing data. Chat sessions are persistent (stored in MySQL), allowing users to return and continue discussions.

**UI:** Resizable drawer (default 40%, draggable border, min 30%, max 70%)
**Auth:** JWT token in WebSocket URL
**Storage:** MySQL only (no Redis for history)
**Vision Model:** OpenRouter gpt-4o ($2.5/$10 per 1M tokens)

---

#### Phase 1: Text Chat (WebSocket + Read-only Tools) ‚úÖ COMPLETE

**1.1 Frontend: Resizable Drawer Component** ‚úÖ COMPLETE
- [x] Create drawer HTML structure (overlay + panel)
- [x] Implement slide-in animation (CSS transitions)
- [x] Add draggable border (JS drag handlers)
- [x] Save/restore width from localStorage
- [x] Close handlers (X button, ESC key, click outside)
- [x] Mobile responsive (full width on mobile)

**Files created:**
- ‚úÖ `app/static/js/chat-drawer.js`
- ‚úÖ `app/static/css/components/chat-drawer.css`

---

**1.2 Frontend: Chat UI Components** ‚úÖ COMPLETE
- [x] Message list container (scrollable)
- [x] User message bubble (right-aligned, blue)
- [x] Assistant message bubble (left-aligned, gray)
- [x] System message (centered, subtle)
- [x] Timestamps (relative time)
- [x] Loading indicator ("typing..." dots)
- [x] Auto-scroll to bottom on new message
- [x] Input field + Send button (with Enter key support)
- [x] Empty state ("–ó–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å –æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏...")

**Files created:**
- ‚úÖ `app/static/js/chat-ui.js`
- ‚úÖ `app/static/css/components/chat-messages.css`

---

**1.3 Frontend: Mock WebSocket Client** ‚úÖ COMPLETE
- [x] Mock connection/disconnect
- [x] Mock send/receive messages
- [x] Mock delay (1-2 sec for responses)
- [x] Mock responses database (10-15 examples)
- [x] Mock error handling
- [x] Mock reconnect logic

**Files created:**
- ‚úÖ `app/static/js/chat-mock.js`

---

**1.4 Frontend: Integration with Recommendations Page** ‚úÖ COMPLETE
- [x] Update "üí¨ –û–±—Å—É–¥–∏—Ç—å —Å FinOps" button handler
- [x] Pass recommendation_id to drawer
- [x] Show recommendation context in drawer header
- [x] Load chat scripts dynamically
- [x] Handle multiple recs (switch chat context)

**Files modified:**
- ‚úÖ `app/static/js/recommendations.js` (updated button)
- ‚úÖ `app/templates/recommendations.html` (added CSS/JS includes)

**Files created:**
- ‚úÖ `app/static/js/chat-integration.js`

---

**1.5 Backend: Database Schema** ‚úÖ COMPLETE
- [x] Create Alembic migration
- [x] Add ChatSession model
- [x] Add ChatMessage model
- [x] Test migration (up/down)
- [x] Fixed: Enum mapping (lowercase values in DB, UPPERCASE enum names in code)

**Schema:**
```sql
chat_sessions:
  - id VARCHAR(36) PRIMARY KEY
  - user_id INT FK
  - recommendation_id INT FK
  - created_at DATETIME
  - last_activity_at DATETIME
  - message_count INT
  - status ENUM('active', 'archived')
  - INDEX (user_id, recommendation_id)
  - INDEX (last_activity_at)

chat_messages:
  - id BIGINT AUTO_INCREMENT PRIMARY KEY
  - session_id VARCHAR(36) FK
  - role ENUM('user', 'assistant', 'system')
  - content TEXT
  - tokens INT
  - created_at DATETIME
  - INDEX (session_id, created_at)
```

**Files created:**
- ‚úÖ `migrations/versions/339d0e4c48e5_add_chat_tables.py`
- ‚úÖ `app/core/models/chat.py`

---

**1.6 Backend: JWT Authentication** ‚úÖ COMPLETE
- [x] Generate shared secret (32 bytes)
- [x] Add JWT_SECRET_KEY to configs
- [x] Create JWT validation function
- [x] Test JWT decode/verify

**Files modified:**
- ‚úÖ `app/config.py`
- ‚úÖ `config.dev.env`
- ‚úÖ `config.agent.env`

**Files created:**
- ‚úÖ `agent_service/auth/jwt_validator.py`
- ‚úÖ `app/api/chat.py` (token generation endpoint)

---

**1.7 Backend: WebSocket Endpoint** ‚úÖ COMPLETE
- [x] Create WS endpoint `/v1/chat/rec/{rec_id}`
- [x] Validate JWT from query param
- [x] Connection manager (track active connections)
- [x] Handle connect/disconnect
- [x] Parse incoming messages
- [x] Send outgoing messages
- [x] Error handling & logging

**Files created:**
- ‚úÖ `agent_service/api/websocket.py`
- ‚úÖ `agent_service/core/connection_manager.py`

---

**1.8 Backend: Session Management** ‚úÖ COMPLETE
- [x] Create session (user_id + rec_id ‚Üí session_id)
- [x] Load session history from DB (last 10 messages)
- [x] Save message to DB
- [x] Update last_activity_at
- [x] Archive old sessions (optional background task)

**Files created:**
- ‚úÖ `agent_service/core/session_manager.py`

---

**1.9 Backend: Read-only Tools** ‚úÖ COMPLETE
- [x] Implement `get_recommendation_details(rec_id)` tool
- [x] Implement `get_resource_details(resource_id)` tool
- [x] Implement `get_provider_pricing(provider, resource_type)` tool
- [x] Implement `calculate_savings(current, new, period)` tool
- [x] Implement `get_migration_risks(resource_id, target_provider)` tool
- [x] Add docstrings for LLM (in Russian)
- [x] Test each tool standalone
- [x] Register tools in LangGraph
- [x] Fixed: Tools use `metrics_snapshot` and `recommendation_type` (not `metrics` / `type`)

**Files created:**
- ‚úÖ `agent_service/tools/recommendation_tools.py`

---

**1.10 Backend: LangGraph Chat Agent** ‚úÖ COMPLETE
- [x] Create FinOps chat system prompt
- [x] Build LangGraph workflow (tools + LLM)
- [x] Add recommendation context to prompt
- [x] Add chat history to state
- [x] Handle tool calls
- [x] Error handling

**Files created:**
- ‚úÖ `agent_service/agents/chat_agent.py`
- ‚úÖ `agent_service/llm/chat_prompts.py`

**System Prompt:**
```
–¢—ã ‚Äî FinOps –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç, –ø–æ–º–æ–≥–∞–µ—à—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–µ–π #{rec_id}.

–ö–æ–Ω—Ç–µ–∫—Å—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:
- –¢–∏–ø: {type}
- –†–µ—Å—É—Ä—Å: {resource_name}
- –≠–∫–æ–Ω–æ–º–∏—è: {savings} ‚ÇΩ/–º–µ—Å

–£ —Ç–µ–±—è –µ—Å—Ç—å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è:
- –ü–æ–ª—É—á–µ–Ω–∏—è –¥–µ—Ç–∞–ª–µ–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
- –ü—Ä–æ—Å–º–æ—Ç—Ä–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ä–µ—Å—É—Ä—Å–∞—Ö
- –°—Ä–∞–≤–Ω–µ–Ω–∏—è —Ü–µ–Ω –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
- –†–∞—Å—á—ë—Ç–∞ —ç–∫–æ–Ω–æ–º–∏–∏
- –û—Ü–µ–Ω–∫–∏ —Ä–∏—Å–∫–æ–≤ –º–∏–≥—Ä–∞—Ü–∏–∏

–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ, –ø–æ –¥–µ–ª—É, —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ —Ü–∏—Ñ—Ä–∞–º–∏. –û–±—â–∞–π—Å—è –ø–æ-—Ä—É—Å—Å–∫–∏.
```

---

**1.11 Backend: WS ‚Üí Agent Integration** ‚úÖ COMPLETE
- [x] On user message ‚Üí invoke agent
- [x] Pass session history to agent
- [x] Stream agent response to WS (or send complete)
- [x] Save user + assistant messages to DB
- [x] Update token count
- [x] Handle agent errors gracefully

**Files modified:**
- ‚úÖ `agent_service/api/websocket.py`

---

**1.12 Frontend: Real WebSocket Client** ‚úÖ COMPLETE
- [x] Replace mock with real WS connection
- [x] Get JWT token from backend (new endpoint)
- [x] Connect to ws://agent:8001/v1/chat/rec/{rec_id}?token=...
- [x] Send/receive JSON messages
- [x] Handle connection errors
- [x] Auto-reconnect on disconnect
- [x] Show connection status in UI

**Files created:**
- ‚úÖ `app/static/js/chat-websocket.js`
- ‚úÖ `app/api/chat.py` (JWT token endpoint)

---

**1.13 Infrastructure: Redis Setup** ‚úÖ COMPLETE
- [x] Add `docker run redis:7-alpine` to run_both.sh
- [x] Add `docker stop infrazen-redis` to stop_both.sh
- [x] Test locally (start/stop)

**Files modified:**
- ‚úÖ `run_both.sh`
- ‚úÖ `stop_both.sh`

**Note:** Production Redis setup deferred to server deployment phase

---

**1.14 Infrastructure: Nginx WebSocket Proxy** ‚úÖ COMPLETE
- [x] Update Nginx config for WS proxy
- [x] Added separate location block for `/agent/v1/chat/`
- [x] Extended timeouts (3600s / 1 hour) for chat sessions
- [x] WebSocket headers (Upgrade, Connection)
- [x] Testing instructions and verification steps

**Files modified:**
- ‚úÖ `agent_service/NGINX_CONFIG.md` (added WS section)

**Key features:**
- Separate location for chat (different timeouts than API)
- No buffering for real-time delivery
- 1-hour timeout for long chat sessions
- Production-ready with HTTPS support

---

**1.15 Testing & Polish** ‚úÖ COMPLETE
- [x] Frontend: Drawer renders correctly
- [x] Frontend: Resize border works (30-70%, default 40%)
- [x] Frontend: Close handlers (X, ESC, click outside)
- [x] Frontend: Chat UI (messages, input, send button)
- [x] Frontend: Typing indicator
- [x] Frontend: Timestamps (relative time)
- [x] Frontend: Auto-scroll
- [x] Frontend: Enter to send, Shift+Enter for new line
- [x] Frontend: Mobile responsive (100% width)
- [x] Backend: WebSocket connection with JWT auth
- [x] Backend: Session persistence (MySQL)
- [x] Backend: Message history loading
- [x] Backend: Tool calling (5 read-only tools)
- [x] Backend: LLM integration (gpt-4o-mini)
- [x] Backend: Error handling
- [x] Backend: Token tracking
- [x] Infrastructure: Redis running locally
- [x] Infrastructure: Nginx config documented
- [x] E2E testing with real user
- [x] Verified tool calls return correct data
- [x] Checked LLM responses in Russian
- [x] Reduced logging noise (console & backend)

**Critical Fixes Applied:**
- ‚úÖ Enum mapping: DB stores lowercase values ('active'), code uses `ChatSessionStatus.ACTIVE`
- ‚úÖ Tools: Fixed field names (`metrics_snapshot`, `recommendation_type`, `resource_name`, `provider_type`)
- ‚úÖ Logging: Silenced frontend debug (behind `INFRAZEN_DATA.debugAgent` flag)
- ‚úÖ Logging: Reduced backend noise (debug-only for connections, suppressed SQLAlchemy INFO)
 - ‚úÖ JWT secrets harmonized: app loads `config.prod.env` with `override=True`; agent prefers `AGENT_SERVICE_JWT_SECRET` and falls back to `JWT_SECRET_KEY`. Production envs set both to the same value to avoid drift across deploys/restarts.

**Commit:** `b8c3e18` - M5 Chat: fix enum mapping; tools use metrics_snapshot; silence frontend console debug; reduce websocket log noise; suppress SQLAlchemy engine INFO logs

---

#### Phase 2: Vision (Screenshot Upload + Analysis)

**2.1 Backend: Image Upload Endpoint**
- [ ] Create POST `/v1/chat/upload` endpoint
- [ ] Accept multipart/form-data (image file)
- [ ] Validate file type (jpg, png, webp)
- [ ] Validate file size (max 5MB)
- [ ] Generate unique image_id (UUID)
- [ ] Save to `/tmp/infrazen-uploads/{image_id}.{ext}`
- [ ] Return image_id to frontend
- [ ] Add cleanup job (delete old images after 1 hour)

**Files to create:**
- `agent_service/api/upload.py`

**Test:** Upload image via curl, check saved to disk

---

**2.2 Backend: Vision Tool**
- [ ] Implement `analyze_screenshot(image_id, question)` tool
- [ ] Load image from disk
- [ ] Convert to base64 for API
- [ ] Call OpenRouter gpt-4o with vision
- [ ] Parse response
- [ ] Cleanup image after analysis
- [ ] Add to LangGraph agent tools

**Files to create:**
- `agent_service/tools/vision_tools.py`

**Test:** Upload image, ask question, get analysis

---

**2.3 Frontend: Image Upload UI**
- [ ] Add üìé button next to input field
- [ ] File picker (image only)
- [ ] Preview uploaded image in chat
- [ ] Upload to agent service (POST /v1/chat/upload)
- [ ] Get image_id from response
- [ ] Send message with image_id: "–ü–æ—Å–º–æ—Ç—Ä–∏ —ç—Ç–æ—Ç –≥—Ä–∞—Ñ–∏–∫ [image:{image_id}]"
- [ ] Display images in chat history

**Files to modify:**
- `app/static/js/chat-ui.js`
- `app/static/css/components/chat-messages.css`

**Test:** Upload image, send with message, see in chat

---

**2.4 Agent: Image Context in Chat**
- [ ] Detect [image:{image_id}] in user message
- [ ] Auto-invoke vision tool
- [ ] Include vision result in agent context
- [ ] Return analysis to user

**Files to modify:**
- `agent_service/agents/chat_agent.py`

**Test:** Send message with image, agent analyzes and responds

---

**2.5 Testing & Polish**
- [ ] Upload various image types
- [ ] Test large images (resize?)
- [ ] Test invalid files
- [ ] Check cleanup job works
- [ ] Test vision analysis quality
- [ ] Image zoom on click
- [ ] Copy image URL
- [ ] Delete uploaded image
- [ ] Show upload progress
- [ ] Show image in assistant response

**Estimated time:** 1 day

---

**Definition of done (Phase 1):** User clicks "üí¨ –û–±—Å—É–¥–∏—Ç—å —Å FinOps", drawer opens with chat UI, can send text messages, agent responds with recommendation context and tool usage, messages persist in DB.

**Definition of done (Phase 2):** User can upload screenshots, agent analyzes them using vision model, provides insights about charts/graphs/configs in context of the recommendation.

### Milestone 6 ‚Äì Analytics Chat (Global Insights)
- [ ] Tools for KPIs, trends, breakdowns, anomalies, top recommendations
- [ ] WebSocket streaming; UI entry on analytics page

Definition of done: agent answers about charts/KPIs and produces concise insights.

### Milestone 7 ‚Äì AI-Generated Report
- [ ] RAG-lite on approved content; generator for HTML/PDF similar to the sample report

Definition of done: one-click report reflects current data with citations and metrics.

### Governance & Safety (Parallel, Non-Disruptive)
- [ ] Guardrails: roles, demo read-only, quotas, cost tracking, audit trail
- [ ] Observability: metrics, logs, alerts for agent (no impact to app)

Notes:
- The agent runs as a separate process, port, env, and systemd unit; the app remains untouched.
- Nginx reloads are zero-downtime; deploy script supports app-only, agent-only, or both.
- Feature flags ensure we can ship incrementally and revert safely.
- CI/CD adds an isolated path for the agent; the app pipeline remains intact.


